{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def show_md(text: str):\n",
    "    display(Markdown(text if text.strip() else \"_<vac√≠o>_\"))\n",
    "\n",
    "async def ask_naive(q: str):\n",
    "    prompt = f\"{q}\\n\\nResponde en m√°ximo 5 l√≠neas claras y concisas.\"\n",
    "    return await rag.aquery(prompt, QueryParam(mode=\"naive\"))\n",
    "\n",
    "async def ask_global(q: str):\n",
    "    prompt = f\"{q}\\n\\nResponde en m√°ximo 5 l√≠neas claras y concisas.\"\n",
    "    return await rag.aquery(prompt, QueryParam(mode=\"global\"))\n",
    "\n",
    "async def ask_llm_only(q: str, temperature: float = 0.6, max_tokens: int = 160):\n",
    "    prompt = f\"{q}\\n\\nResponde en m√°ximo 5 l√≠neas claras y concisas.\"\n",
    "    return await deepseepk_model_if_cache(prompt, temperature=temperature, max_tokens=max_tokens)\n",
    "\n",
    "async def compare(q: str, do_llm: bool = True):\n",
    "    n = await ask_naive(q)\n",
    "    g = await ask_global(q)\n",
    "    show_md(f\"### ‚ùì {q}\\n\\n**üß© Naive RAG**\\n\\n{n}\\n\\n**üåê GraphRAG (Global)**\\n\\n{g}\")\n",
    "    if do_llm:\n",
    "        l = await ask_llm_only(q)\n",
    "        show_md(f\"**üß† Puro LLM**\\n\\n{l}\")\n",
    "\n",
    "# Ejemplo:\n",
    "# await compare(\"¬øQui√©nes son los protagonistas?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aad8c62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.72it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m compare(\u001b[33m\"\u001b[39m\u001b[33m¬øQui√©nes son los protagonistas?\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mcompare\u001b[39m\u001b[34m(q, do_llm)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompare\u001b[39m(q: \u001b[38;5;28mstr\u001b[39m, do_llm: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     n = \u001b[38;5;28;01mawait\u001b[39;00m ask_naive(q)\n\u001b[32m     20\u001b[39m     g = \u001b[38;5;28;01mawait\u001b[39;00m ask_global(q)\n\u001b[32m     21\u001b[39m     show_md(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m### ‚ùì \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m**üß© Naive RAG**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m**üåê GraphRAG (Global)**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mask_naive\u001b[39m\u001b[34m(q)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mask_naive\u001b[39m(q: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      7\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResponde en m√°ximo 5 l√≠neas claras y concisas.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m rag.aquery(prompt, QueryParam(mode=\u001b[33m\"\u001b[39m\u001b[33mnaive\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/JUAN PABLO /SEMESTRE 2025-2/PLN/Prueba-PLN/nano_graphrag/graphrag.py:264\u001b[39m, in \u001b[36mGraphRAG.aquery\u001b[39m\u001b[34m(self, query, param)\u001b[39m\n\u001b[32m    253\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m global_query(\n\u001b[32m    254\u001b[39m         query,\n\u001b[32m    255\u001b[39m         \u001b[38;5;28mself\u001b[39m.chunk_entity_relation_graph,\n\u001b[32m   (...)\u001b[39m\u001b[32m    261\u001b[39m         asdict(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m    262\u001b[39m     )\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m param.mode == \u001b[33m\"\u001b[39m\u001b[33mnaive\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m naive_query(\n\u001b[32m    265\u001b[39m         query,\n\u001b[32m    266\u001b[39m         \u001b[38;5;28mself\u001b[39m.chunks_vdb,\n\u001b[32m    267\u001b[39m         \u001b[38;5;28mself\u001b[39m.text_chunks,\n\u001b[32m    268\u001b[39m         param,\n\u001b[32m    269\u001b[39m         \u001b[38;5;28mself\u001b[39m.tokenizer_wrapper,\n\u001b[32m    270\u001b[39m         asdict(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m    271\u001b[39m     )\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown mode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam.mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/JUAN PABLO /SEMESTRE 2025-2/PLN/Prueba-PLN/nano_graphrag/_op.py:1122\u001b[39m, in \u001b[36mnaive_query\u001b[39m\u001b[34m(query, chunks_vdb, text_chunks_db, query_param, tokenizer_wrapper, global_config)\u001b[39m\n\u001b[32m   1119\u001b[39m chunks_ids = [r[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[32m   1120\u001b[39m chunks = \u001b[38;5;28;01mawait\u001b[39;00m text_chunks_db.get_by_ids(chunks_ids)\n\u001b[32m-> \u001b[39m\u001b[32m1122\u001b[39m maybe_trun_chunks = \u001b[43mtruncate_list_by_token_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_token_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_param\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnaive_max_token_for_text_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer_wrapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# ‰º†ÂÖ• wrapper\u001b[39;49;00m\n\u001b[32m   1127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1128\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTruncate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(maybe_trun_chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chunks\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1129\u001b[39m section = \u001b[33m\"\u001b[39m\u001b[33m--New Chunk--\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join([c[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m maybe_trun_chunks])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/JUAN PABLO /SEMESTRE 2025-2/PLN/Prueba-PLN/nano_graphrag/_utils.py:180\u001b[39m, in \u001b[36mtruncate_list_by_token_size\u001b[39m\u001b[34m(list_data, key, max_token_size, tokenizer_wrapper)\u001b[39m\n\u001b[32m    178\u001b[39m tokens = \u001b[32m0\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(list_data):\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     tokens += \u001b[38;5;28mlen\u001b[39m(tokenizer_wrapper.encode(\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)) + \u001b[32m1\u001b[39m \u001b[38;5;66;03m# Èò≤Âæ°ÊÄßÔºåÊ®°ÊãüÈÄöËøá\\nÊãºÊé•ÂàóË°®ÁöÑÊÉÖÂÜµ\u001b[39;00m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tokens > max_token_size:\n\u001b[32m    182\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m list_data[:i]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/JUAN PABLO /SEMESTRE 2025-2/PLN/Prueba-PLN/nano_graphrag/_op.py:1124\u001b[39m, in \u001b[36mnaive_query.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1119\u001b[39m chunks_ids = [r[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[32m   1120\u001b[39m chunks = \u001b[38;5;28;01mawait\u001b[39;00m text_chunks_db.get_by_ids(chunks_ids)\n\u001b[32m   1122\u001b[39m maybe_trun_chunks = truncate_list_by_token_size(\n\u001b[32m   1123\u001b[39m     chunks,\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     key=\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m   1125\u001b[39m     max_token_size=query_param.naive_max_token_for_text_unit,\n\u001b[32m   1126\u001b[39m     tokenizer_wrapper=tokenizer_wrapper, \u001b[38;5;66;03m# ‰º†ÂÖ• wrapper\u001b[39;00m\n\u001b[32m   1127\u001b[39m )\n\u001b[32m   1128\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTruncate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(maybe_trun_chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chunks\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1129\u001b[39m section = \u001b[33m\"\u001b[39m\u001b[33m--New Chunk--\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join([c[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m maybe_trun_chunks])\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "await compare(\"¬øQui√©nes son los protagonistas?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a6d1310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.43it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# === Ejemplo de comparaci√≥n ===\u001b[39;00m\n\u001b[32m      2\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mQuienes son los protagonista?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m ans_naive  = \u001b[38;5;28;01mawait\u001b[39;00m ask_naive(question)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# ans_global = await ask_global(question)\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ans_llm    = await ask_llm_only(question, temperature=0.5, max_tokens=180)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPregunta:\u001b[39m\u001b[33m\"\u001b[39m);   show_md(question)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mask_naive\u001b[39m\u001b[34m(q, max_tokens)\u001b[39m\n\u001b[32m     24\u001b[39m prompt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResponde en m√°ximo 5 l√≠neas claras y concisas.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# OJO: no se pasan kwargs aqu√≠; GraphRAG no acepta temperature/max_tokens.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m rag.aquery(prompt, QueryParam(mode=\u001b[33m\"\u001b[39m\u001b[33mnaive\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/JUAN PABLO /SEMESTRE 2025-2/PLN/Prueba-PLN/nano_graphrag/graphrag.py:264\u001b[39m, in \u001b[36mGraphRAG.aquery\u001b[39m\u001b[34m(self, query, param)\u001b[39m\n\u001b[32m    253\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m global_query(\n\u001b[32m    254\u001b[39m         query,\n\u001b[32m    255\u001b[39m         \u001b[38;5;28mself\u001b[39m.chunk_entity_relation_graph,\n\u001b[32m   (...)\u001b[39m\u001b[32m    261\u001b[39m         asdict(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m    262\u001b[39m     )\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m param.mode == \u001b[33m\"\u001b[39m\u001b[33mnaive\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m naive_query(\n\u001b[32m    265\u001b[39m         query,\n\u001b[32m    266\u001b[39m         \u001b[38;5;28mself\u001b[39m.chunks_vdb,\n\u001b[32m    267\u001b[39m         \u001b[38;5;28mself\u001b[39m.text_chunks,\n\u001b[32m    268\u001b[39m         param,\n\u001b[32m    269\u001b[39m         \u001b[38;5;28mself\u001b[39m.tokenizer_wrapper,\n\u001b[32m    270\u001b[39m         asdict(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m    271\u001b[39m     )\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown mode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam.mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/JUAN PABLO /SEMESTRE 2025-2/PLN/Prueba-PLN/nano_graphrag/_op.py:1122\u001b[39m, in \u001b[36mnaive_query\u001b[39m\u001b[34m(query, chunks_vdb, text_chunks_db, query_param, tokenizer_wrapper, global_config)\u001b[39m\n\u001b[32m   1119\u001b[39m chunks_ids = [r[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[32m   1120\u001b[39m chunks = \u001b[38;5;28;01mawait\u001b[39;00m text_chunks_db.get_by_ids(chunks_ids)\n\u001b[32m-> \u001b[39m\u001b[32m1122\u001b[39m maybe_trun_chunks = \u001b[43mtruncate_list_by_token_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_token_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_param\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnaive_max_token_for_text_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer_wrapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# ‰º†ÂÖ• wrapper\u001b[39;49;00m\n\u001b[32m   1127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1128\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTruncate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(maybe_trun_chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chunks\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1129\u001b[39m section = \u001b[33m\"\u001b[39m\u001b[33m--New Chunk--\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join([c[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m maybe_trun_chunks])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/JUAN PABLO /SEMESTRE 2025-2/PLN/Prueba-PLN/nano_graphrag/_utils.py:180\u001b[39m, in \u001b[36mtruncate_list_by_token_size\u001b[39m\u001b[34m(list_data, key, max_token_size, tokenizer_wrapper)\u001b[39m\n\u001b[32m    178\u001b[39m tokens = \u001b[32m0\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(list_data):\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     tokens += \u001b[38;5;28mlen\u001b[39m(tokenizer_wrapper.encode(\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)) + \u001b[32m1\u001b[39m \u001b[38;5;66;03m# Èò≤Âæ°ÊÄßÔºåÊ®°ÊãüÈÄöËøá\\nÊãºÊé•ÂàóË°®ÁöÑÊÉÖÂÜµ\u001b[39;00m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tokens > max_token_size:\n\u001b[32m    182\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m list_data[:i]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/JUAN PABLO /SEMESTRE 2025-2/PLN/Prueba-PLN/nano_graphrag/_op.py:1124\u001b[39m, in \u001b[36mnaive_query.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1119\u001b[39m chunks_ids = [r[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[32m   1120\u001b[39m chunks = \u001b[38;5;28;01mawait\u001b[39;00m text_chunks_db.get_by_ids(chunks_ids)\n\u001b[32m   1122\u001b[39m maybe_trun_chunks = truncate_list_by_token_size(\n\u001b[32m   1123\u001b[39m     chunks,\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     key=\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m   1125\u001b[39m     max_token_size=query_param.naive_max_token_for_text_unit,\n\u001b[32m   1126\u001b[39m     tokenizer_wrapper=tokenizer_wrapper, \u001b[38;5;66;03m# ‰º†ÂÖ• wrapper\u001b[39;00m\n\u001b[32m   1127\u001b[39m )\n\u001b[32m   1128\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTruncate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(maybe_trun_chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chunks\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1129\u001b[39m section = \u001b[33m\"\u001b[39m\u001b[33m--New Chunk--\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join([c[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m maybe_trun_chunks])\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# === Ejemplo de comparaci√≥n ===\n",
    "question = \"Quienes son los protagonista?\"\n",
    "\n",
    "ans_naive  = await ask_naive(question)\n",
    "# ans_global = await ask_global(question)\n",
    "# ans_llm    = await ask_llm_only(question, temperature=0.5, max_tokens=180)\n",
    "\n",
    "print(\"Pregunta:\");   show_md(question)\n",
    "print(\"NAIVE RAG:\\n\");   show_md(ans_naive)\n",
    "# print(\"\\nGRAPH RAG (GLOBAL):\\n\"); show_md(ans_global)\n",
    "# print(\"\\nPURO LLM:\\n\");    show_md(ans_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4a21c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING_DIR: ./nano_graphrag_cache_deepseek_TEST\n",
      "enable_naive_rag: True\n",
      "chunks_vdb is None? -> False\n",
      "vdb_chunks.json bytes: 296428\n",
      "kv_store_text_chunks.json bytes: 638909\n",
      "KV chunks: 99\n",
      "Ejemplo de IDs: ['chunk-21453a7fcc3285739b8573a25e0e6893', 'chunk-c0949c6a647fd1346bc913f8f9e13fcc', 'chunk-97895642add93678aae24271f6d4f93e']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json, os\n",
    "from pathlib import Path\n",
    "from examples.using_deepseek_as_llm import (\n",
    "    deepseepk_model_if_cache,   # LLM ya listo y con cache opcional\n",
    "    local_st_embeddings,\n",
    "    WORKING_DIR,\n",
    ")\n",
    "\n",
    "print(\"WORKING_DIR:\", WORKING_DIR)\n",
    "print(\"enable_naive_rag:\", rag.enable_naive_rag)\n",
    "print(\"chunks_vdb is None? ->\", rag.chunks_vdb is None)\n",
    "\n",
    "def size(p): \n",
    "    return Path(p).stat().st_size if Path(p).exists() else 0\n",
    "\n",
    "vdb_path = f\"{WORKING_DIR}/vdb_chunks.json\"\n",
    "kv_path  = f\"{WORKING_DIR}/kv_store_text_chunks.json\"\n",
    "\n",
    "print(\"vdb_chunks.json bytes:\", size(vdb_path))\n",
    "print(\"kv_store_text_chunks.json bytes:\", size(kv_path))\n",
    "\n",
    "if size(kv_path):\n",
    "    with open(kv_path, encoding=\"utf-8\") as f:\n",
    "        d = json.load(f)\n",
    "    print(\"KV chunks:\", len(d))\n",
    "    print(\"Ejemplo de IDs:\", list(d.keys())[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
